<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">

		
		<meta name="description" content="IA locales ou distantes, outils, et un chef d'orchestre nommÃ© n8n">
		<meta name="author" content="Antonin Brugnot">

		<meta name="mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<title>IA locales ou distantes, outils, et un chef d'orchestre nommÃ© n8n</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<!-- Slide d'introduction -->
				<section>
					<h1>IA locales ou distantes, outils, et un chef d'orchestre nommÃ© n8n</h1>
					<p>
						<small>Antonin Brugnot - Onepoint</small>
					</p>
					<aside class="notes">
						Bonjour ! Aujourd'hui on va explorer comment orchestrer des agents IA avec n8n, une plateforme d'automatisation simple et visuelle. On va connecter des modÃ¨les IA locaux avec Ollama ou distants, et des outils grÃ¢ce au protocole MCP. Une approche concrÃ¨te pour crÃ©er des assistants IA vraiment utilesâ€¦ et maÃ®trisÃ©s.
					</aside>
				</section>

				<!-- Section 1: PrÃ©sentation de n8n -->
				<section>
					<section>
						<h1>ğŸ”§ PrÃ©sentation de n8n</h1>
					</section>

					<section>
						<h2>Pourquoi n8n ?</h2>
						<ul>
							<li class="fragment">ğŸ”— Connecter vos outils du quotidien</li>
							<li class="fragment">ğŸ¨ Interface visuelle intuitive</li>
							<li class="fragment">ğŸš€ No-code/Low-code</li>
							<li class="fragment">ğŸ” ContrÃ´le de vos donnÃ©es</li>
							<li class="fragment">ğŸ’° Open Source</li>
						</ul>
						<aside class="notes">
							n8n permet de connecter facilement tous vos outils : API, bases de donnÃ©es, services cloud. L'interface visuelle rend l'automatisation accessible mÃªme aux non-dÃ©veloppeurs. Et contrairement Ã  Zapier, vous gardez le contrÃ´le de vos donnÃ©es.
						</aside>
					</section>

					<section>
						<h2>Selfhosted ou Cloud ?</h2>
						<div style="display: flex; justify-content: space-around;">
							<div style="flex: 1;">
								<h3>ğŸ  Self-hosted</h3>
								<ul>
									<li>ContrÃ´le total</li>
									<li>DonnÃ©es privÃ©es</li>
									<li>Personnalisation</li>
									<li>Docker/K8s</li>
								</ul>
							</div>
							<div style="flex: 1;">
								<h3>â˜ï¸ Cloud</h3>
								<ul>
									<li>SimplicitÃ©</li>
									<li>Maintenance incluse</li>
									<li>ScalabilitÃ©</li>
									<li>Support officiel</li>
								</ul>
							</div>
						</div>
						<aside class="notes">
							Deux options : self-hosted pour garder le contrÃ´le total, ou cloud pour la simplicitÃ©. Aujourd'hui on se concentre sur le self-hosted avec Docker.
						</aside>
					</section>

					<section>
						<h2>Cas d'usage classiques</h2>
						<ul>
							<li class="fragment">ğŸ“§ Automatisation email</li>
							<li class="fragment">ğŸ”„ Synchronisation de donnÃ©es</li>
							<li class="fragment">ğŸ“Š Rapports automatiques</li>
							<li class="fragment">ğŸ”” Notifications intelligentes</li>
							<li class="fragment">ğŸ› ï¸ Outils internes</li>
						</ul>
						<aside class="notes">
							Les cas d'usage vont de la simple automatisation d'emails Ã  la crÃ©ation d'outils internes complexes. Avec l'IA, on peut maintenant crÃ©er des workflows vraiment intelligents.
						</aside>
					</section>

					<section>
						<h2>FonctionnalitÃ©s clÃ©s</h2>
						<ul>
							<li class="fragment">âš¡ <strong>Triggers</strong> : Webhook, Schedule, Email...</li>
							<li class="fragment">ğŸ“ <strong>Variables</strong> : Stockage de donnÃ©es entre Ã©tapes</li>
							<li class="fragment">ğŸ§© <strong>Nodes</strong> : +400 intÃ©grations disponibles</li>
							<li class="fragment">ğŸš¨ <strong>Gestion d'erreurs</strong> : Retry, fallback...</li>
							<li class="fragment">ğŸ”’ <strong>Credentials</strong> : Stockage sÃ©curisÃ©</li>
						</ul>
						<aside class="notes">
							Les triggers dÃ©clenchent vos workflows, les variables permettent de passer des donnÃ©es entre Ã©tapes, plus de 400 nodes disponibles, et une gestion d'erreurs robuste.
						</aside>
					</section>
				</section>

				<!-- Section 2: Avec les agents IA -->
				<section>
					<section>
						<h1>ğŸ¤– Avec les agents IA</h1>
					</section>

					<section>
						<h2>AI Agent Node</h2>
						<ul>
							<li class="fragment">ğŸ§  <strong>Cerveau central</strong> : Prend des dÃ©cisions</li>
							<li class="fragment">ğŸ’­ <strong>Prompts systÃ¨me</strong> : DÃ©finit le comportement</li>
							<li class="fragment">ğŸ”— <strong>IntÃ©gration native</strong> : ConnectÃ© aux workflows</li>
							<li class="fragment">ğŸ“‹ <strong>Planning</strong> : DÃ©compose les tÃ¢ches complexes</li>
						</ul>
						<aside class="notes">
							L'AI Agent Node est le cerveau de votre workflow. Il peut prendre des dÃ©cisions, planifier des actions et s'adapter selon le contexte.
						</aside>
					</section>

					<section>
						<h2>Ollama local vs distant</h2>
						<div style="display: flex; justify-content: space-around;">
							<div style="flex: 1;">
								<h3>ğŸ  Ollama Local</h3>
								<ul>
									<li>ğŸ”’ DonnÃ©es privÃ©es</li>
									<li>âš¡ Pas de latence rÃ©seau</li>
									<li>ğŸ’° Pas de coÃ»t API</li>
									<li>ğŸ–¥ï¸ GPU/CPU local</li>
								</ul>
							</div>
							<div style="flex: 1;">
								<h3>â˜ï¸ ModÃ¨les distants</h3>
								<ul>
									<li>ğŸš€ Performance optimale</li>
									<li>ğŸ”„ Toujours Ã  jour</li>
									<li>ğŸ“ˆ ScalabilitÃ©</li>
									<li>ğŸ’³ Pay-per-use</li>
								</ul>
							</div>
						</div>
						<aside class="notes">
							Ollama permet d'utiliser des modÃ¨les comme Llama, Qwen, ou Mistral en local. Les modÃ¨les distants offrent plus de puissance mais moins de contrÃ´le.
						</aside>
					</section>

					<section>
						<h2>MÃ©moire</h2>
						<ul>
							<li class="fragment">ğŸ§  <strong>MÃ©moire de conversation</strong> : Contexte multi-tours</li>
							<li class="fragment">ğŸ“š <strong>Vector Store</strong> : Recherche sÃ©mantique</li>
							<li class="fragment">ğŸ’¾ <strong>Variables persistantes</strong> : Ã‰tat entre workflows</li>
							<li class="fragment">ğŸ”„ <strong>Historique</strong> : Apprentissage des interactions</li>
						</ul>
						<aside class="notes">
							La mÃ©moire permet aux agents de maintenir le contexte, d'apprendre des interactions prÃ©cÃ©dentes et d'accÃ©der Ã  une base de connaissances.
						</aside>
					</section>

					<section>
						<h2>Outils (via MCP)</h2>
						<ul>
							<li class="fragment">ğŸŒ <strong>Web scraping</strong> : Playwright, Puppeteer</li>
							<li class="fragment">ğŸ—‚ï¸ <strong>Fichiers</strong> : Lecture, Ã©criture, traitement</li>
							<li class="fragment">ğŸ“Š <strong>Bases de donnÃ©es</strong> : SQL, NoSQL</li>
							<li class="fragment">ğŸ“§ <strong>Communications</strong> : Email, Slack, Teams</li>
							<li class="fragment">ğŸ› ï¸ <strong>APIs diverses</strong> : CRM, ERP, Cloud...</li>
						</ul>
						<aside class="notes">
							Le protocole MCP (Model Context Protocol) permet aux agents d'utiliser des outils externes : navigateur web, fichiers, bases de donnÃ©es, APIs...
						</aside>
					</section>

					<section>
						<h2>Architecture complÃ¨te</h2>
						<img src="img/architecture.png" alt="Architecture n8n + IA" style="max-width: 80%;">
						<aside class="notes">
							Voici l'architecture complÃ¨te : l'utilisateur dÃ©clenche n8n, qui utilise un agent IA connectÃ© Ã  des modÃ¨les locaux ou distants, avec mÃ©moire et outils.
						</aside>
					</section>
				</section>

				<!-- Section 3: DÃ©mo live -->
				<section>
					<section>
						<h1>ğŸš€ DÃ©mo live : n8n sandbox</h1>
					</section>

					<section>
						<h2>Les sources : docker-compose.yml</h2>
						<pre><code class="hljs yaml" data-trim>
						postgres:
							image: postgres:15
							...

						n8n:
							build: ./n8n
							...
							ports:
							- 5678:5678

						ollama:
							image: ollama/ollama:latest
							...
							ports:
							- "11435:11434"
						
						# services:
						#   n8n:
						#     models:
						#       - llm
						# models:
						#   llm:
						#     model: ai/model
						</code></pre>
						<aside class="notes">
							Voici la configuration Docker : PostgreSQL pour la persistence, n8n pour l'orchestration, Ollama pour l'IA locale, et Qdrant pour les embeddings. Note : Docker Model Runner avec sa syntaxe `models:` est disponible dans Docker Compose mais pas encore supportÃ© par Podman Compose.
						</aside>
					</section>

					<section>
						<h2>Les workflows</h2>
						<ul>
							<li class="fragment">ğŸ“§ <strong>Mail.json</strong> : Assistant email intelligent</li>
							<li class="fragment">ğŸ—‚ï¸ <strong>Indexation.json</strong> : Traitement de documents</li>
							<li class="fragment">ğŸ” <strong>Search in Index.json</strong> : Recherche sÃ©mantique</li>
							<li class="fragment">ğŸ’¬ <strong>Customer Support Chat.json</strong> : Chatbot support</li>
						</ul>
						<aside class="notes">
							On va voir 4 workflows : traitement d'emails avec IA, indexation de documents, recherche sÃ©mantique et chatbot de support client.
						</aside>
					</section>

					<section>
						<h2>Demo time! ğŸ¬</h2>
						<h3>DÃ©marrage du stack</h3>
						<pre><code class="hljs bash" data-trim>
						# Lancement des services
						./start.sh

						# Configuration d'Ollama local
						./setup-ollama.sh

						# Import des workflows
						./import-n8n-data.sh
						</code></pre>
						<aside class="notes">
							Maintenant, place Ã  la dÃ©mo ! On va dÃ©marrer le stack, configurer Ollama avec des modÃ¨les locaux, et importer nos workflows.
						</aside>
					</section>

					<section data-background="lightblue">
						<h1>ğŸ¯ DÃ©mo en direct</h1>
						<p>http://localhost:5678</p>
						<aside class="notes">
							[Ici, faire la dÃ©monstration live des workflows]
						</aside>
					</section>
				</section>

				<!-- Section 4: Conclusion et questions -->
				<section>
					<section>
						<h1>â“ Conclusion et questions</h1>
					</section>

					<section>
						<h2>Ce qu'on a vu</h2>
						<ul>
							<li class="fragment">âœ… n8n comme chef d'orchestre</li>
							<li class="fragment">âœ… IntÃ©gration IA locale (Ollama) et distante</li>
							<li class="fragment">âœ… Agents avec mÃ©moire et outils</li>
							<li class="fragment">âœ… Protocole MCP pour Ã©tendre les capacitÃ©s</li>
							<li class="fragment">âœ… DÃ©mo concrÃ¨te avec workflows</li>
						</ul>
						<aside class="notes">
							RÃ©cap de ce qu'on a couvert : n8n comme plateforme centrale, IA locale et distante, agents intelligents avec mÃ©moire et outils, et une dÃ©mo pratique.
						</aside>
					</section>

					<section>
						<h2>Pour aller plus loin</h2>
						<ul>
							<li class="fragment">ğŸ”— <strong>Sources</strong> : GitHub avec docker-compose</li>
							<li class="fragment">ğŸ“š <strong>Documentation</strong> : n8n.io et ollama.ai</li>
							<li class="fragment">ğŸŒ <strong>CommunautÃ©</strong> : Discord n8n et forums</li>
							<li class="fragment">ğŸš€ <strong>Ã‰volutions</strong> : Nouveaux nodes IA en permanence</li>
						</ul>
						<aside class="notes">
							Pour continuer : toutes les sources sont disponibles, la doc officielle est excellente, et la communautÃ© trÃ¨s active.
						</aside>
					</section>

					<section>
						<h2 class="r-fit-text">Questions ? ğŸ¤”</h2>
						<p class="fragment">Merci pour votre attention !</p>
					</section>

					<section data-auto-animate>
						<h2 data-id="code-title">bio.yaml</h2>
						<pre data-id="code-animation"><code class="hljs yaml" data-trim data-line-numbers><script type="text/template">
							first_name: "Antonin"
							family_name: "Brugnot"
							company: "Onepoint"
							twitter: null
							personal_info:
							  email: "a.brugnot@groupeonepoint.com"
							  birth: "21st July, 1987"
							  photo: "tronche_joviale.png"
							  location: "Nantes"
							summary: "Lead Tech, DevOps, FullStack, Cloud, IA"
						</script></code></pre>
					</section>

					<section>
						<h2>Contact & Sources</h2>
						<p>ğŸ“§ a.brugnot@groupeonepoint.com</p>
						<p>ğŸ”— GitHub : antoBrugnot/n8n</p>
						<p>ğŸ¢ Onepoint - Nantes</p>
					</section>
				</section>	            
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,
				slideNumber: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [RevealNotes, RevealMarkdown, RevealHighlight ]
			});
		</script>
	</body>
</html>
